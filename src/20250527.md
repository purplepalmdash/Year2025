# 20250527
### 1. bridged(x86+arm64)
#### 1.1 environment
Machines:     

```
Nuc: 10.171.172.3/24(br0), fedora x86_64 release 42(Adams)
arm64: 10.171.172.20/24(br0), Ubuntu 25.04 aarch64
```
Disk:      

```
controller(x86):   # cp openstack1.qcow2 bridged_openstack_controller.qcow2, 31G
compute(arm64): # cp hope_openstack_compute.qcow2 bridged_compute.qcow2, 42G
```
#### 1.2 vms
Controller:     

![./images/2025_05_27_10_05_51_439x282.jpg](./images/2025_05_27_10_05_51_439x282.jpg)


![./images/2025_05_27_10_04_51_488x439.jpg](./images/2025_05_27_10_04_51_488x439.jpg)

two nics:    

![./images/2025_05_27_10_05_11_695x587.jpg](./images/2025_05_27_10_05_11_695x587.jpg)


Compute:    

![./images/2025_05_27_10_02_28_456x444.jpg](./images/2025_05_27_10_02_28_456x444.jpg)

![./images/2025_05_27_10_03_03_445x439.jpg](./images/2025_05_27_10_03_03_445x439.jpg)

two nics:    

![./images/2025_05_27_10_03_47_630x543.jpg](./images/2025_05_27_10_03_47_630x543.jpg)

#### 1.3 Basic configurations
Controller(10.171.172.21):    

![./images/2025_05_27_10_08_31_724x528.jpg](./images/2025_05_27_10_08_31_724x528.jpg)

```
# vim /etc/systemd/system/network-online.target.wants/NetworkManager-wait-online.service
...
Type=oneshot
ExecStart=/usr/bin/nm-online -s -q
RemainAfterExit=yes
TimeoutStartSec=5sec
```
Compute(10.171.172.22):    

![./images/2025_05_27_10_11_50_345x182.jpg](./images/2025_05_27_10_11_50_345x182.jpg)

virgl:    

![./images/2025_05_27_10_13_22_540x399.jpg](./images/2025_05_27_10_13_22_540x399.jpg)

![./images/2025_05_27_10_13_30_484x479.jpg](./images/2025_05_27_10_13_30_484x479.jpg)


```
# vim /etc/systemd/system/network-online.target.wants/systemd-networkd-wait-online.service
...
TimeoutStartSec=5sec
```
then start the vm with command line: `virsh start bridged_openstack_compute`    

Wrong:    
The IP address range changed. need re-deploy 
### 2. re-deploy
Re-create image:       

```
x86: qemu-img create -f qcow2 -b ubuntu2204openstackbase.qcow2 bridged_openstack_controller.qcow2 -F qcow2
arm64: # qemu-img create -f qcow2 -b openstack_arm64_baase_150G.qcow2 -F qcow2 bridged_compute.qcow2
```
Set hostname:     

```
hostnamectl set-hostname controller
hostnamectl set-hostname compute
```
Each host:      

```
cat >> /etc/hosts << EOF
10.171.172.21 controller
10.171.172.22 compute
EOF
timedatectl set-ntp true && timedatectl set-timezone Asia/Shanghai
apt update -y && apt upgrade -y
```
Controller:      

```
apt install -y python3-openstackclient  mariadb-server python3-pymysql
cat > /etc/mysql/mariadb.conf.d/99-openstack.cnf << EOF
[mysqld]
bind-address = 0.0.0.0

default-storage-engine = innodb
innodb_file_per_table = on
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8
EOF
service mysql restart

mysql_secure_installation

输入数据库密码：回车
可以在没有适当授权的情况下登录到MariaDB root用户，当前已收到保护：n
设置root用户密码：n
删除匿名用户：y
不允许远程root登录：n
删除测试数据库：y
重新加载数据库：y

apt install -y rabbitmq-server
rabbitmqctl add_user openstack openstackhuhy
rabbitmqctl set_permissions openstack ".*" ".*" ".*"
apt install -y memcached python3-memcache
vim /etc/memcached.conf

-l 0.0.0.0

service memcached restart

mysql -uroot -p000000
CREATE DATABASE keystone;
GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'keystonehuhy';
quit
apt install -y keystone
vim /etc/keystone/keystone.conf
[DEFAULT]
log_dir = /var/log/keystone
[application_credential]
[assignment]
[auth]
[cache]
[catalog]
[cors]
[credential]

[database]
connection = mysql+pymysql://keystone:keystonehuhy@controller/keystone

[domain_config]
[endpoint_filter]
[endpoint_policy]
[eventlet_server]
[extra_headers]
Distribution = Ubuntu
[federation]
[fernet_receipts]
[fernet_tokens]
[healthcheck]
[identity]
[identity_mapping]
[jwt_tokens]
[ldap]
[memcache]
[oauth1]
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[policy]
[profiler]
[receipt]
[resource]
[revoke]
[role]
[saml]
[security_compliance]
[shadow_users]

[token]
provider = fernet
[tokenless_auth]
[totp]
[trust]
[unified_limit]
[wsgi]

su -s /bin/sh -c "keystone-manage db_sync" keystone
keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
keystone-manage credential_setup --keystone-user keystone --keystone-group keystone
keystone-manage bootstrap --bootstrap-password 000000 --bootstrap-admin-url http://controller:5000/v3/ --bootstrap-internal-url http://controller:5000/v3/ --bootstrap-public-url http://controller:5000/v3/ --bootstrap-region-id RegionOne
echo "ServerName controller" >> /etc/apache2/apache2.conf 
service apache2 restart

cat > /etc/keystone/admin-openrc.sh << EOF
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=000000
export OS_AUTH_URL=http://controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2
EOF

source /etc/keystone/admin-openrc.sh
openstack project create --domain default --description "Service Project" service
openstack token issue
mysql -uroot -p000000
CREATE DATABASE glance;
GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'glancehuhy';
quit

openstack user create --domain default --password glance glance; \
openstack role add --project service --user glance admin; \
openstack service create --name glance --description "OpenStack Image" image

openstack endpoint create --region RegionOne image public http://controller:9292; \
openstack endpoint create --region RegionOne image internal http://controller:9292; \
openstack endpoint create --region RegionOne image admin http://controller:9292

apt install -y glance
vim /etc/glance/glance-api.conf
[DEFAULT]
[barbican]
[barbican_service_user]
[cinder]
[cors]
[database]
connection = mysql+pymysql://glance:glancehuhy@controller/glance

[glance_store]
stores = file,http
default_store = file
filesystem_store_datadir = /var/lib/glance/images/

[image_format]
disk_formats = ami,ari,aki,vhd,vhdx,vmdk,raw,qcow2,vdi,iso,ploop.root-tar

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = glance
password = glance

[paste_deploy]
flavor = keystone
su -s /bin/sh -c "glance-manage db_sync" glance
service glance-api restart

mysql -uroot -p000000
CREATE DATABASE placement;
GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'placementhuhy';
quit

openstack user create --domain default --password placement placement; \
openstack role add --project service --user placement admin; \
openstack service create --name placement --description "Placement API" placement

openstack endpoint create --region RegionOne placement public http://controller:8778; \
openstack endpoint create --region RegionOne placement internal http://controller:8778; \
openstack endpoint create --region RegionOne placement admin http://controller:8778

apt install -y placement-api

vim /etc/placement/placement.conf

[DEFAULT]

[api]
auth_strategy = keystone

[cors]

[keystone_authtoken]
auth_url = http://controller:5000/v3
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = placement
password = placement

[placement_database]
connection = mysql+pymysql://placement:placementhuhy@controller/placement

su -s /bin/sh -c "placement-manage db sync" placement
service apache2 restart
placement-status upgrade check


mysql -uroot -p000000
CREATE DATABASE nova_api;
CREATE DATABASE nova;
CREATE DATABASE nova_cell0;
GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'novahuhy';
GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'novahuhy';
GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'novahuhy';
quit

openstack user create --domain default --password nova nova; \
openstack role add --project service --user nova admin; \
openstack service create --name nova --description "OpenStack Compute" compute

openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1; \
openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1; \
openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1

apt install -y nova-api nova-conductor nova-novncproxy nova-scheduler

vim /etc/nova/nova.conf

[DEFAULT]
log_dir = /var/log/nova
lock_path = /var/lock/nova
state_path = /var/lib/nova
transport_url = rabbit://openstack:openstackhuhy@controller:5672/
my_ip = 10.171.172.21

[api]
auth_strategy = keystone
[api_database]
connection = mysql+pymysql://nova:novahuhy@controller/nova_api
[barbican]
[barbican_service_user]
[cache]
[cinder]
[compute]
[conductor]
[console]
[consoleauth]
[cors]
[cyborg]

[database]
connection = mysql+pymysql://nova:novahuhy@controller/nova
[devices]
[ephemeral_storage_encryption]
[filter_scheduler]

[glance]
api_servers = http://controller:9292
[guestfs]
[healthcheck]
[hyperv]
[image_cache]
[ironic]
[key_manager]
[keystone]

[keystone_authtoken]
www_authenticate_uri = http://controller:5000/
auth_url = http://controller:5000/
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = nova
[libvirt]
[metrics]
[mks]
[neutron]
[notifications]

[oslo_concurrency]
lock_path = /var/lib/nova/tmp
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[oslo_reports]
[pci]

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controller:5000/v3
username = placement
password = placement
[powervm]
[privsep]
[profiler]
[quota]
[rdp]
[remote_debug]
[scheduler]
[serial_console]
[service_user]
[spice]
[upgrade_levels]

[vault]
[vendordata_dynamic_auth]
[vmware]

[vnc]
enabled = true
server_listen = $my_ip
server_proxyclient_address = $my_ip
[workarounds]
[wsgi]
[zvm]

[cells]
enable = False
[os_region_name]
openstack = 

su -s /bin/sh -c "nova-manage api_db sync" nova
su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova
su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova
su -s /bin/sh -c "nova-manage db sync" nova
su -s /bin/sh -c "nova-manage cell_v2 list_cells" nova

cat > /root/nova-restart.sh <<EOF 
#!bin/bash
# 处理api服务
service nova-api restart
# 处理资源调度服务
service nova-scheduler restart
# 处理数据库服务
service nova-conductor restart
# 处理vnc远程窗口服务
service nova-novncproxy restart
EOF

bash nova-restart.sh
```
nova compute:    

```
apt install -y nova-compute
vi /etc/nova/nova.conf
# cat /etc/nova/nova.conf 
[DEFAULT]
log_dir = /var/log/nova
lock_path = /var/lock/nova
state_path = /var/lib/nova
transport_url = rabbit://openstack:openstackhuhy@controller
my_ip = 10.171.172.22

[api]
auth_strategy = keystone
[api_database]
[barbican]
[barbican_service_user]
[cache]
[cinder]
[compute]
[conductor]
[console]
[consoleauth]
[cors]
[cyborg]
[database]
[devices]
[ephemeral_storage_encryption]
[filter_scheduler]

[glance]
api_servers = http://controller:9292
[guestfs]
[healthcheck]
[hyperv]
[image_cache]
[ironic]
[key_manager]
[keystone]

[keystone_authtoken]
www_authenticate_uri = http://controller:5000/
auth_url = http://controller:5000/
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = nova
[libvirt]
[metrics]
[mks]
[neutron]
[notifications]

[oslo_concurrency]
lock_path = /var/lib/nova/tmp
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[oslo_reports]
[pci]

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controller:5000/v3
username = placement
password = placement
[powervm]
[privsep]
[profiler]
[quota]
[rdp]
[remote_debug]
[scheduler]
[serial_console]
[service_user]
[spice]
[upgrade_levels]
[vault]
[vendordata_dynamic_auth]
[vmware]

[vnc]
enabled = true
server_listen = 0.0.0.0
server_proxyclient_address = $my_ip
novncproxy_base_url = http://10.171.172.21:6080/vnc_auto.html
[workarounds]
[wsgi]
[zvm]
[cells]
enable = False
[os_region_name]
openstack =

service nova-compute restart
```
(Controller): Discover the available compute node:      

```
openstack compute service list --service nova-compute
su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova
vim /etc/nova/nova.conf
[scheduler]
discover_hosts_in_cells_interval = 300
```

neutron:    

```
mysql -uroot -p000000
CREATE DATABASE neutron;
GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'neutronhuhy';
quit

openstack user create --domain default --password neutron neutron; \
openstack role add --project service --user neutron admin; \
openstack service create --name neutron --description "OpenStack Networking" network

openstack endpoint create --region RegionOne network public http://controller:9696; \
openstack endpoint create --region RegionOne network internal http://controller:9696; \
openstack endpoint create --region RegionOne network admin http://controller:9696

cat >> /etc/sysctl.conf << EOF
# 用于控制系统是否开启对数据包源地址的校验，关闭
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
# 开启二层转发设备
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
EOF

modprobe br_netfilter
sysctl -p

apt install -y neutron-server neutron-plugin-ml2  neutron-l3-agent neutron-dhcp-agent  neutron-metadata-agent neutron-openvswitch-agent

vim /etc/neutron/neutron.conf
[DEFAULT]
core_plugin = ml2
service_plugins = router
allow_overlapping_ips = true
auth_strategy = keystone
state_path = /var/lib/neutron
dhcp_agent_notification = true
allow_overlapping_ips = true
notify_nova_on_port_status_changes = true
notify_nova_on_port_data_changes = true
transport_url = rabbit://openstack:openstackhuhy@controller

[agent]
root_helper = "sudo /usr/bin/neutron-rootwrap /etc/neutron/rootwrap.conf"

[database]
connection = mysql+pymysql://neutron:neutronhuhy@controller/neutron

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron

[nova]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = nova
password = nova

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp

vim /etc/neutron/plugins/ml2/ml2_conf.ini
[DEFAULT]
[ml2]
type_drivers = flat,vlan,vxlan,gre
tenant_network_types = vxlan
mechanism_drivers = openvswitch,l2population
extension_drivers = port_security

[ml2_type_flat]
flat_networks = physnet1

[ml2_type_geneve]

[ml2_type_gre]

[ml2_type_vlan]

[ml2_type_vxlan]
vni_ranges = 1:1000

[ovs_driver]

[securitygroup]
enable_ipset = true
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
[sriov_driver]


vim /etc/neutron/plugins/ml2/openvswitch_agent.ini
[DEFAULT]
[agent]
l2_population = True
tunnel_types = vxlan
prevent_arp_spoofing = True

[dhcp]
[network_log]

[ovs]
local_ip = 10.171.172.21
bridge_mappings = physnet1:br-enpkkk
[securitygroup]

vim /etc/neutron/l3_agent.ini
[DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
external_network_bridge =
[agent]
[network_log]
[ovs]

vim /etc/neutron/dhcp_agent.ini
[DEFAULT]
interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = True
[agent]
[ovs]

vim /etc/neutron/metadata_agent.ini
[DEFAULT]
nova_metadata_host = controller
metadata_proxy_shared_secret = huhy
[agent]
[cache]

vim /etc/nova/nova.conf
default]
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSlnterfaceDriver

[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = neutron
service_metadata_proxy = true
metadata_proxy_shared_secret = huhy

su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron

service nova-api restart
ovs-vsctl add-br br-enpkkk
ovs-vsctl add-port  br-enpkkk enp2s0
cat > neutron-restart.sh  <<EOF
#!bin/bash
# 提供neutron服务
service neutron-server restart
# 提供ovs服务
service neutron-openvswitch-agent restart
# 提供地址动态服务
service neutron-dhcp-agent restart
# 提供元数据服务
service neutron-metadata-agent restart
# 提供三层网络服务
service neutron-l3-agent restart
EOF

bash neutron-restart.sh

```
(neutron) compute node:     

```
cat >> /etc/sysctl.conf << EOF
# 用于控制系统是否开启对数据包源地址的校验，关闭
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
# 开启二层转发设备
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
EOF

modprobe br_netfilter
sysctl -p

apt install -y neutron-openvswitch-agent

vim /etc/neutron/neutron.conf

[DEFAULT]
core_plugin = ml2
service_plugins = router
auth_strategy = keystone
state_path = /var/lib/neutron
allow_overlapping_ips = true
transport_url = rabbit://openstack:openstackhuhy@controller

[agent]
root_helper = "sudo /usr/bin/neutron-rootwrap /etc/neutron/rootwrap.conf"
[cache]
[cors]
[database]
[healthcheck]
[ironic]

[keystone_authtoken]
www_authenticate_uri = http://controller:5000
auth_url = http://controller:5000
memcached_servers = controller:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron

[nova]

[oslo_concurrency]
lock_path = /var/lib/neutron/tmp
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[oslo_reports]
[placement]
[privsep]
[quotas]
[ssl]

vim /etc/neutron/plugins/ml2/openvswitch_agent.ini
[DEFAULT]
[agent]
l2_population = True
tunnel_types = vxlan
prevent_arp_spoofing = True
[dhcp]
[network_log]

[ovs]
local_ip = 10.171.172.22
bridge_mappings = physnet1:br-enpkkk
[securitygroup]
enable_security_group = True
firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver

vim /etc/nova/nova.conf

[DEFAULT]
linuxnet_interface_driver = nova.network.linux_net.LinuxOVSlnterfaceDriver
vif_plugging_is_fatal = true
vif_pligging_timeout = 300

[neutron]
auth_url = http://controller:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = neutron

service nova-compute restart

ovs-vsctl add-br br-enpkkk
ovs-vsctl add-port br-enpkkk enp4s0

service neutron-openvswitch-agent restart
```
(controller), dashboard:      

```
apt install -y openstack-dashboard

vim /etc/openstack-dashboard/local_settings.py

# 配置仪表板以在控制器节点上使用OpenStack服务
OPENSTACK_HOST = "controller"

# 在Dashboard configuration部分中，允许主机访问Dashboard
ALLOWED_HOSTS = ["*"]

# 配置memcached会话存储服务
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'

CACHES = {
    'default': {
         'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
         'LOCATION': 'controller:11211',
    }
}

# 启用Identity API版本3
OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOST

# 启用对域的支持
OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True

# 配置API版本
OPENSTACK_API_VERSIONS = {
    "identity": 3,
    "image": 2,
    "volume": 3,
}

# 将Default配置为通过仪表板创建的用户的默认域
OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"

# 将用户配置为通过仪表板创建的用户的默认角色
OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"

# 启用卷备份
OPENSTACK_CINDER_FEATURES = {
    'enable_backup': True,
}

# 配置时区
TIME_ZONE = "Asia/Shanghai"
systemctl reload apache2
```
Create network:      

```
source /etc/keystone/admin-openrc.sh
openstack router create Ext-Router
openstack network create --internal --provider-network-type vxlan int-net
openstack subnet create int-net-sub --network int-net --subnet-range 177.77.77.0/24 --gateway 177.77.77.1 --dns-nameserver 114.114.114.114
openstack router add subnet Ext-Router int-net-sub
openstack network create --provider-physical-network physnet1 --provider-network-type flat  --external ext-net
openstack subnet create ext-net-sub --network ext-net --subnet-range 10.171.172.21/24  --allocation-pool start=10.171.172.100,end=10.171.172.200 --gateway 10.171.172.1 --dns-nameserver 114.114.114.114 --dhcp
openstack router set Ext-Router --external-gateway ext-net
```

dashboard: 10.171.172.21/horizon:    

![./images/2025_05_27_11_31_02_505x469.jpg](./images/2025_05_27_11_31_02_505x469.jpg)

admin/000000/default:    

![./images/2025_05_27_11_31_21_514x504.jpg](./images/2025_05_27_11_31_21_514x504.jpg)

![./images/2025_05_27_11_31_55_878x672.jpg](./images/2025_05_27_11_31_55_878x672.jpg)

Create flavor:    

```
openstack flavor create --vcpus 4 --ram 6124 --disk 25 C4-6124MB-25G
```
Create image:      

```
openstack image create "redroid12_32bit" --file redroid1232bit.img --disk-format raw --container-format bare --public
```
### 3. adjust/verification
compute node:     

```
# apt install -y nova-compute-lxc
# cat /etc/nova/nova-compute.conf 
[DEFAULT]
compute_driver=libvirt.LibvirtDriver
[libvirt]
virt_type=lxc
# apt install ./libvirt/libvirt-daemon-driver-lxc_8.0.0-1ubuntu7.11_arm64.deb 
# cd virt/libvirt/
# cp config.py driver.py guest.py /usr/lib/python3/dist-packages/nova/virt/libvirt/
# cd /usr/lib/python3/dist-packages/nova/ && find . | grep pyc$ | xargs -I % mv % %.kk
# cd ~/ubuntu2204openstack/
```
All node:      

```
crontab -e
@reboot sleep 10 && modprobe binder_linux devices="binder,hwbinder,vndbinder" && modprobe nbd

# cat /etc/modprobe.d/blacklist.conf
......
blacklist x_tables
```
controller node:     

```
# cp config.py driver.py guest.py /usr/lib/python3/dist-packages/nova/virt/libvirt/
# cd /usr/lib/python3/dist-packages/nova/ && find . | grep pyc$ | xargs -I % mv % %.kk
```
Now you could create the instance from horizon:     

![./images/2025_05_27_14_32_19_1411x410.jpg](./images/2025_05_27_14_32_19_1411x410.jpg)

Examine the running instance:     

```
root@compute:~# virsh -c lxc:/// list
 Id     Name                State
-------------------------------------
 1397   instance-00000004   running
 1410   instance-00000005   running
 1488   instance-00000006   running

root@compute:~# virsh -c lxc:/// console instance-00000005
Connected to domain 'instance-00000005'
Escape character is ^] (Ctrl + ])
/system/bin/sh: No controlling tty: open /dev/tty: No such device or address
/system/bin/sh: warning: won't have full job control
console:/ $ getprop | grep boot | grep com                                     
[dev.bootcomplete]: [1]
[ro.boottime.vendor.hwcomposer-2-1]: [154468717840]
[sys.boot_completed]: [1]
[sys.bootstat.first_boot_completed]: [1]
```
Remove all of the security roles:    

![./images/2025_05_27_14_34_19_1129x525.jpg](./images/2025_05_27_14_34_19_1129x525.jpg)

Add icmp in:    

![./images/2025_05_27_14_34_47_710x605.jpg](./images/2025_05_27_14_34_47_710x605.jpg)

add icmp out:    

![./images/2025_05_27_14_35_16_723x690.jpg](./images/2025_05_27_14_35_16_723x690.jpg)

add tcp in:    

![./images/2025_05_27_14_35_54_704x635.jpg](./images/2025_05_27_14_35_54_704x635.jpg)

add tcp out:    

![./images/2025_05_27_14_36_13_713x628.jpg](./images/2025_05_27_14_36_13_713x628.jpg)

add udp in:   

![./images/2025_05_27_14_36_35_688x624.jpg](./images/2025_05_27_14_36_35_688x624.jpg)

add udp out:    

![./images/2025_05_27_14_36_55_653x584.jpg](./images/2025_05_27_14_36_55_653x584.jpg)

all rules:    

![./images/2025_05_27_14_37_14_1098x600.jpg](./images/2025_05_27_14_37_14_1098x600.jpg)

Running test:     

![./images/2025_05_27_14_38_40_1154x862.jpg](./images/2025_05_27_14_38_40_1154x862.jpg)

virgl based result:     

![./images/2025_05_27_14_44_47_513x793.jpg](./images/2025_05_27_14_44_47_513x793.jpg)

![./images/2025_05_27_14_45_04_501x724.jpg](./images/2025_05_27_14_45_04_501x724.jpg)

![./images/2025_05_27_14_45_17_526x784.jpg](./images/2025_05_27_14_45_17_526x784.jpg)

### 4. Add new compute node(raw gpu)
Start host via usb disk:     

![./images/2025_05_27_14_59_40_601x274.jpg](./images/2025_05_27_14_59_40_601x274.jpg)

Install with hwe kernel:    

![./images/2025_05_27_15_03_33_1021x403.jpg](./images/2025_05_27_15_03_33_1021x403.jpg)

Install to external usb disk:     

![./images/2025_05_27_15_04_10_679x208.jpg](./images/2025_05_27_15_04_10_679x208.jpg)

![./images/2025_05_27_15_04_47_402x238.jpg](./images/2025_05_27_15_04_47_402x238.jpg)

After installation:    

![./images/2025_05_27_15_08_46_727x359.jpg](./images/2025_05_27_15_08_46_727x359.jpg)

![./images/2025_05_27_15_09_32_695x379.jpg](./images/2025_05_27_15_09_32_695x379.jpg)

Initial Steps:      

```
Change wait-on-line timeout to 5sec
add net.ifnames=0 biosdevname=0 in grub configuration and update-grub2
reboot
```
network:     

```
ip addr add 10.171.172.24/24 dev eth0
ip link set eth0 up
ip route add default via 10.171.172.1 dev eth0
rm -f /etc/resolv.conf 
echo "nameserver 223.5.5.5">/etc/resolv.conf
chattr +i /etc/resolv.conf
apt update -y
apt install -y vim nethogs iotop net-tools s-tui iperf3
```
Configure network:     

```
# cat /etc/netplan/eth0.yaml
network:
  version: 2
  ethernets:
    eth0:
      dhcp4: false
      addresses: [10.171.172.23/24]
      gateway4: 10.171.172.1
    eth1:
      dhcp4: false
```
Added crontab, blacklist, then reboot:     

```
@reboot sleep 10 && sysctl -p && modprobe binder_linux devices="binder,hwbinder,vndbinder" && modprobe nbd
# vim /etc/modprobe.d/blacklist.conf
blacklist x_tables
```
set hostname:     

```
hostnamectl set-hostname
cat >> /etc/hosts << EOF
10.171.172.21 controller
10.171.172.22 compute
10.171.172.23 gpu
EOF
timedatectl set-ntp true
timedatectl set-timezone Asia/Shanghai
apt install chrony -y
```
Install nova:      

```
# apt install -y nova-compute
# vim /etc/nova/nova.conf
# service nova-compute restart
```
The nova.conf content:      

```
[DEFAULT]
log_dir = /var/log/nova
lock_path = /var/lock/nova
state_path = /var/lib/nova
transport_url = rabbit://openstack:openstackhuhy@controller
my_ip = 10.171.172.23

[api]
auth_strategy = keystone
[api_database]
[barbican]
[barbican_service_user]
[cache]
[cinder]
[compute]
[conductor]
[console]
[consoleauth]
[cors]
[cyborg]
[database]
[devices]
[ephemeral_storage_encryption]
[filter_scheduler]

[glance]
api_servers = http://controller:9292
[guestfs]
[healthcheck]
[hyperv]
[image_cache]
[ironic]
[key_manager]
[keystone]

[keystone_authtoken]
www_authenticate_uri = http://controller:5000/
auth_url = http://controller:5000/
memcached_servers = controller:11211
auth_type = password
project_domain_name = Default
user_domain_name = Default
project_name = service
username = nova
password = nova
[libvirt]
[metrics]
[mks]
[neutron]
[notifications]

[oslo_concurrency]
lock_path = /var/lib/nova/tmp
[oslo_messaging_amqp]
[oslo_messaging_kafka]
[oslo_messaging_notifications]
[oslo_messaging_rabbit]
[oslo_middleware]
[oslo_policy]
[oslo_reports]
[pci]

[placement]
region_name = RegionOne
project_domain_name = Default
project_name = service
auth_type = password
user_domain_name = Default
auth_url = http://controller:5000/v3
username = placement
password = placement
[powervm]
[privsep]
[profiler]
[quota]
[rdp]
[remote_debug]
[scheduler]
[serial_console]
[service_user]
[spice]
[upgrade_levels]
[vault]
[vendordata_dynamic_auth]
[vmware]

[vnc]
enabled = true
server_listen = 0.0.0.0
server_proxyclient_address = $my_ip
novncproxy_base_url = http://10.171.172.21:6080/vnc_auto.html
[workarounds]
[wsgi]
[zvm]
[cells]
enable = False
[os_region_name]
openstack =
```
Switch to controller:    

```
# openstack compute service list --service nova-compute
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
| ID                                   | Binary       | Host    | Zone | Status  | State | Updated At                 |
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
| 083e7170-9d65-4ab7-8ad9-50a6639480be | nova-compute | compute | nova | enabled | up    | 2025-05-27T08:13:15.000000 |
| cc6cc325-5483-4929-b437-36a1260db353 | nova-compute | gpu     | nova | enabled | up    | 2025-05-27T08:13:17.000000 |
+--------------------------------------+--------------+---------+------+---------+-------+----------------------------+
```
gpu node:      

```
cat >> /etc/sysctl.conf << EOF
# 用于控制系统是否开启对数据包源地址的校验，关闭
net.ipv4.conf.all.rp_filter=0
net.ipv4.conf.default.rp_filter=0
# 开启二层转发设备
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
EOF
modprobe br_netfilter && sysctl -p
```
Install neutron, configure :     

```
apt install -y neutron-openvswitch-agent
vim /etc/neutron/neutron.conf 
vim /etc/neutron/plugins/ml2/openvswitch_agent.ini
```
`neutron.conf` and `openvswitch_agent.ini` could be copied from compute node and adjust to the gpu node ip address.     

adjust `/etc/nova/nova.conf`  the same as in compute node.   

restart the service and add bridge:    

```
service nova-compute restart
ovs-vsctl add-br br-enpkkk
ovs-vsctl add-port br-enpkkk  eth1
```
Restart the neutron service:      

```
service neutron-openvswitch-agent restart
```
Switch to lxc:      

```
apt install lxc-utils
apt remove apparmor --purge
apt install -y nova-compute-lxc
apt remove libvirt-daemon-driver-lxc --purge
apt install -y ./libvirt-daemon-driver-lxc_8.0.0-1ubuntu7.11_arm64.deb
 cp config.py driver.py guest.py /usr/lib/python3/dist-packages/nova/virt/libvirt/
cp addedxml_* /etc/
cd /usr/lib/python3/dist-packages/nova/ && find . | grep pyc$ | xargs -I % mv % %.kk
systemctl restart nova-compute
ufw disable
```
amd 520 result:    

![./images/2025_05_27_17_02_20_528x947.jpg](./images/2025_05_27_17_02_20_528x947.jpg)

![./images/2025_05_27_17_02_54_518x869.jpg](./images/2025_05_27_17_02_54_518x869.jpg)

change to 1920x1080, 120fps:    

![./images/2025_05_27_17_13_27_534x810.jpg](./images/2025_05_27_17_13_27_534x810.jpg)

![./images/2025_05_27_17_19_05_526x822.jpg](./images/2025_05_27_17_19_05_526x822.jpg)

rx550 4G:     

![./images/2025_05_27_17_45_25_544x886.jpg](./images/2025_05_27_17_45_25_544x886.jpg)

![./images/2025_05_27_17_45_38_563x914.jpg](./images/2025_05_27_17_45_38_563x914.jpg)

![./images/2025_05_27_17_46_12_546x591.jpg](./images/2025_05_27_17_46_12_546x591.jpg)

![./images/2025_05_27_17_50_02_524x882.jpg](./images/2025_05_27_17_50_02_524x882.jpg)

