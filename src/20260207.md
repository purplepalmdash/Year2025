# 20260207
### 1. vllm
Install modelscope:     

```
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple modelscope "modelscope[cli]" -U --break-system-packages
modelscope download Qwen/Qwen2.5-72B-Instruct-AWQ
```
vllm docker image download.   

```
 sudo docker pull vllm/vllm-openai:nightly
sudo docker run --runtime nvidia --gpus all   --ipc=host   --shm-size=32g   -v /home/dash/.cache/modelscope/hub:/root/.cache/modelscope/hub:ro   -p 8000:8000   --name vllm-qwen25-72b-awq-new   -e LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/tegra:/lib/x86_64-linux-gnu   vllm/vllm-openai:nightly   --host 0.0.0.0   --port 8000   --model /root/.cache/modelscope/hub/models/Qwen/Qwen2___5-72B-Instruct-AWQ   --quantization awq   --dtype auto   --tensor-parallel-size 1   --max-model-len 15760 --gpu-memory-utilization 0.96 --enforce-eager   --max-num-batched-tokens 2048  --max-num-seqs 1
```
Test:    

```
$ curl http://localhost:8000/v1/models
{"object":"list","data":[{"id":"/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-72B-Instruct-AWQ","object":"model","created":1770467297,"owned_by":"vllm","root":"/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-72B-Instruct-AWQ","parent":null,"max_model_len":15760,"permission":[{"id":"modelperm-90f7e2eaa7b4e065","object":"model_permission","created":1770467297,"allow_create_engine":false,"allow_sampling":true,"allow_logprobs":true,"allow_search_indices":false,"allow_view":true,"allow_fine_tuning":false,"organization":"*","group":null,"is_blocking":false}]}]}
```
Simple introduction:     

```
$ curl http://localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-72B-Instruct-AWQ",
    "messages": [{"role": "user", "content": "你好，请用中文自我介绍"}],
    "max_tokens": 100
  }'
{"id":"chatcmpl-a4c0d23f267397ae","object":"chat.completion","created":1770467364,"model":"/root/.cache/modelscope/hub/models/Qwen/Qwen2___5-72B-Instruct-AWQ","choices":[{"index":0,"message":{"role":"assistant","content":"你好，我是Qwen，由阿里云研发的超大规模语言模型。我能够生成各种类型的文本，如文章、故事、诗歌等，并能根据不同的场景和需求进行调整。我还能够回答问题、提供信息查询服务，以及进行多轮对话，以更好地理解和满足用户的需求。很高兴认识你，希望可以成为你的得力助手！","refusal":null,"annotations":null,"audio":null,"function_call":null,"tool_calls":[],"reasoning":null},"logprobs":null,"finish_reason":"stop","stop_reason":null,"token_ids":null}],"service_tier":null,"system_fingerprint":null,"usage":{"prompt_tokens":35,"total_tokens":111,"completion_tokens":76,"prompt_tokens_details":null},"prompt_logprobs":null,"prompt_token_ids":null,"kv_transfer_params":null}
```
